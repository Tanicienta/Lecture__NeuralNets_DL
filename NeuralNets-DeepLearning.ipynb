{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets and Deep Learning\n",
    "#### Slides:\n",
    "http://bit.ly/NeuralNets_Dojo_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation Section\n",
    "### 1.1 TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip 9.0.1 from /opt/conda/lib/python3.6/site-packages (python 3.6)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for pip\n",
      "Reading https://pypi.python.org/simple/pip/\n",
      "Downloading https://pypi.python.org/packages/11/b6/abcb525026a4be042b486df43905d6893fb04f05aac21c32c638e939e447/pip-9.0.1.tar.gz#md5=35f01da33009719497f01a4ba69d63c9\n",
      "Best match: pip 9.0.1\n",
      "Processing pip-9.0.1.tar.gz\n",
      "Writing /tmp/easy_install-rvf4fbdn/pip-9.0.1/setup.cfg\n",
      "Running pip-9.0.1/setup.py -q bdist_egg --dist-dir /tmp/easy_install-rvf4fbdn/pip-9.0.1/egg-dist-tmp-3z2gqi1e\n",
      "creating /opt/conda/lib/python3.6/site-packages/pip-9.0.1-py3.6.egg\n",
      "Extracting pip-9.0.1-py3.6.egg to /opt/conda/lib/python3.6/site-packages\n",
      "Adding pip 9.0.1 to easy-install.pth file\n",
      "Installing pip script to /opt/conda/bin\n",
      "Installing pip3 script to /opt/conda/bin\n",
      "Installing pip3.6 script to /opt/conda/bin\n",
      "\n",
      "Installed /opt/conda/lib/python3.6/site-packages/pip-9.0.1-py3.6.egg\n",
      "Processing dependencies for pip\n",
      "Finished processing dependencies for pip\n",
      "Searching for six\n",
      "Reading https://pypi.python.org/simple/six/\n",
      "Downloading https://pypi.python.org/packages/b3/b2/238e2590826bfdd113244a40d9d3eb26918bd798fc187e2360a8367068db/six-1.10.0.tar.gz#md5=34eed507548117b2ab523ab14b2f8b55\n",
      "Best match: six 1.10.0\n",
      "Processing six-1.10.0.tar.gz\n",
      "Writing /tmp/easy_install-m6_8nenx/six-1.10.0/setup.cfg\n",
      "Running six-1.10.0/setup.py -q bdist_egg --dist-dir /tmp/easy_install-m6_8nenx/six-1.10.0/egg-dist-tmp-rv0630t2\n",
      "creating /opt/conda/lib/python3.6/site-packages/six-1.10.0-py3.6.egg\n",
      "Extracting six-1.10.0-py3.6.egg to /opt/conda/lib/python3.6/site-packages\n",
      "Adding six 1.10.0 to easy-install.pth file\n",
      "\n",
      "Installed /opt/conda/lib/python3.6/site-packages/six-1.10.0-py3.6.egg\n",
      "Processing dependencies for six\n",
      "Finished processing dependencies for six\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files found matching '.coveragerc'\n",
      "warning: no previously-included files found matching '.mailmap'\n",
      "warning: no previously-included files found matching '.travis.yml'\n",
      "warning: no previously-included files found matching '.landscape.yml'\n",
      "warning: no previously-included files found matching 'pip/_vendor/Makefile'\n",
      "warning: no previously-included files found matching 'tox.ini'\n",
      "warning: no previously-included files found matching 'dev-requirements.txt'\n",
      "warning: no previously-included files found matching 'appveyor.yml'\n",
      "no previously-included directories found matching '.github'\n",
      "no previously-included directories found matching '.travis'\n",
      "no previously-included directories found matching 'docs/_build'\n",
      "no previously-included directories found matching 'contrib'\n",
      "no previously-included directories found matching 'tasks'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'documentation/_build'\n",
      "zip_safe flag not set; analyzing archive contents...\n",
      "__pycache__.six.cpython-36: module references __path__\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "# easy_install --upgrade pip\n",
    "# easy_install --upgrade six "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (43.5MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow)\n",
      "Collecting tensorflow-tensorboard<0.2.0,>=0.1.0 (from tensorflow)\n",
      "  Downloading tensorflow_tensorboard-0.1.5-py3-none-any.whl (2.2MB)\n",
      "Collecting protobuf>=3.3.0 (from tensorflow)\n",
      "  Downloading protobuf-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (6.2MB)\n",
      "Collecting numpy>=1.11.0 (from tensorflow)\n",
      "  Downloading numpy-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
      "Collecting werkzeug>=0.11.10 (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "  Downloading Werkzeug-0.12.2-py2.py3-none-any.whl (312kB)\n",
      "Requirement already satisfied: bleach==1.5.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "Requirement already satisfied: html5lib==0.9999999 in /opt/conda/lib/python3.6/site-packages (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "Collecting markdown>=2.6.8 (from tensorflow-tensorboard<0.2.0,>=0.1.0->tensorflow)\n",
      "  Downloading Markdown-2.6.9.tar.gz (271kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from protobuf>=3.3.0->tensorflow)\n",
      "Building wheels for collected packages: markdown\n",
      "  Running setup.py bdist_wheel for markdown: started\n",
      "  Running setup.py bdist_wheel for markdown: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/46/10/c93e17ae86ae3b3a919c7b39dad3b5ccf09aeb066419e5c1e5\n",
      "Successfully built markdown\n",
      "Installing collected packages: werkzeug, protobuf, markdown, numpy, tensorflow-tensorboard, tensorflow\n",
      "Successfully installed markdown-2.6.9 numpy-1.13.1 protobuf-3.4.0 tensorflow-1.3.0 tensorflow-tensorboard-0.1.5 werkzeug-0.12.2\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "#Validate your Installation\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.0.8-py2.py3-none-any.whl (276kB)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading PyYAML-3.12.tar.gz (253kB)\n",
      "Collecting scipy>=0.14 (from keras)\n",
      "  Downloading scipy-0.19.1-cp36-cp36m-manylinux1_x86_64.whl (48.2MB)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/f7/79/13f3a12cd723892437c0cfbde1230ab4d82947ff7b3839a4fc\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, scipy, keras\n",
      "Successfully installed keras-2.0.8 pyyaml-3.12 scipy-0.19.1\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By default, Keras will use TensorFlow as its tensor manipulation library :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-2.0.2-cp36-cp36m-manylinux1_x86_64.whl (14.6MB)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Collecting pytz (from matplotlib)\n",
      "  Downloading pytz-2017.2-py2.py3-none-any.whl (484kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.0,!=2.0.4,!=2.1.2,!=2.1.6,>=1.5.6 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Installing collected packages: pytz, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 matplotlib-2.0.2 pytz-2017.2\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Neural Nets Examples\n",
    "### 2.1 Diabetes - Pima Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Description:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Number of Instances: 768\n",
    "\n",
    "6. Number of Attributes: 8 plus class \n",
    "\n",
    "7. For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "\n",
    "8. Missing Attribute Values: Yes\n",
    "\n",
    "9. Class Distribution: (class value 1 is interpreted as \"tested positive for\n",
    "   diabetes\")\n",
    "\n",
    "   Class Value  Number of instances\n",
    "   0            500\n",
    "   1            268\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(=>) Download the dataset from this url and save the file as \"pima.csv\"\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense  #Just Dense or fully connected neurons\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score, f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPerformance(history):\n",
    "    # summarize history for accuracy  \n",
    "\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # summarize history for loss  \n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima.csv\", delimiter=\",\")\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.     148.      72.    ...,    0.627   50.       1.   ]\n",
      " [   1.      85.      66.    ...,    0.351   31.       0.   ]\n",
      " [   8.     183.      64.    ...,    0.672   32.       1.   ]\n",
      " ..., \n",
      " [   5.     121.      72.    ...,    0.245   30.       0.   ]\n",
      " [   1.     126.      60.    ...,    0.349   47.       1.   ]\n",
      " [   1.      93.      70.    ...,    0.315   23.       0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, kernel_initializer=\"uniform\", activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "optimizer='adam' #adam, sgd\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/140\n",
      "0s - loss: 0.6854 - acc: 0.6466 - val_loss: 0.6736 - val_acc: 0.6429\n",
      "Epoch 2/140\n",
      "0s - loss: 0.6662 - acc: 0.6531 - val_loss: 0.6673 - val_acc: 0.6429\n",
      "Epoch 3/140\n",
      "0s - loss: 0.6568 - acc: 0.6531 - val_loss: 0.6670 - val_acc: 0.6429\n",
      "Epoch 4/140\n",
      "0s - loss: 0.6508 - acc: 0.6547 - val_loss: 0.6632 - val_acc: 0.6494\n",
      "Epoch 5/140\n",
      "0s - loss: 0.6406 - acc: 0.6564 - val_loss: 0.6548 - val_acc: 0.6364\n",
      "Epoch 6/140\n",
      "0s - loss: 0.6274 - acc: 0.6743 - val_loss: 0.6489 - val_acc: 0.5974\n",
      "Epoch 7/140\n",
      "0s - loss: 0.6214 - acc: 0.6889 - val_loss: 0.6392 - val_acc: 0.6039\n",
      "Epoch 8/140\n",
      "0s - loss: 0.6092 - acc: 0.6857 - val_loss: 0.6304 - val_acc: 0.6494\n",
      "Epoch 9/140\n",
      "0s - loss: 0.6076 - acc: 0.6759 - val_loss: 0.6286 - val_acc: 0.6364\n",
      "Epoch 10/140\n",
      "0s - loss: 0.6019 - acc: 0.6792 - val_loss: 0.6286 - val_acc: 0.6299\n",
      "Epoch 11/140\n",
      "0s - loss: 0.5964 - acc: 0.6775 - val_loss: 0.6134 - val_acc: 0.6494\n",
      "Epoch 12/140\n",
      "0s - loss: 0.5919 - acc: 0.6857 - val_loss: 0.6119 - val_acc: 0.6169\n",
      "Epoch 13/140\n",
      "0s - loss: 0.5908 - acc: 0.6792 - val_loss: 0.6060 - val_acc: 0.6364\n",
      "Epoch 14/140\n",
      "0s - loss: 0.5916 - acc: 0.6873 - val_loss: 0.6071 - val_acc: 0.6688\n",
      "Epoch 15/140\n",
      "0s - loss: 0.5843 - acc: 0.6987 - val_loss: 0.6008 - val_acc: 0.6818\n",
      "Epoch 16/140\n",
      "0s - loss: 0.5853 - acc: 0.6938 - val_loss: 0.5987 - val_acc: 0.6948\n",
      "Epoch 17/140\n",
      "0s - loss: 0.5820 - acc: 0.7003 - val_loss: 0.6114 - val_acc: 0.6883\n",
      "Epoch 18/140\n",
      "0s - loss: 0.5885 - acc: 0.6906 - val_loss: 0.6071 - val_acc: 0.6883\n",
      "Epoch 19/140\n",
      "0s - loss: 0.5791 - acc: 0.6971 - val_loss: 0.6050 - val_acc: 0.6753\n",
      "Epoch 20/140\n",
      "0s - loss: 0.5752 - acc: 0.7020 - val_loss: 0.6032 - val_acc: 0.6948\n",
      "Epoch 21/140\n",
      "0s - loss: 0.5780 - acc: 0.6971 - val_loss: 0.5925 - val_acc: 0.6753\n",
      "Epoch 22/140\n",
      "0s - loss: 0.5734 - acc: 0.6954 - val_loss: 0.6159 - val_acc: 0.6818\n",
      "Epoch 23/140\n",
      "0s - loss: 0.5756 - acc: 0.7085 - val_loss: 0.5899 - val_acc: 0.6883\n",
      "Epoch 24/140\n",
      "0s - loss: 0.5729 - acc: 0.6889 - val_loss: 0.5852 - val_acc: 0.6948\n",
      "Epoch 25/140\n",
      "0s - loss: 0.5701 - acc: 0.7117 - val_loss: 0.6028 - val_acc: 0.6494\n",
      "Epoch 26/140\n",
      "0s - loss: 0.5700 - acc: 0.7215 - val_loss: 0.5845 - val_acc: 0.7078\n",
      "Epoch 27/140\n",
      "0s - loss: 0.5698 - acc: 0.7134 - val_loss: 0.5828 - val_acc: 0.6883\n",
      "Epoch 28/140\n",
      "0s - loss: 0.5640 - acc: 0.7182 - val_loss: 0.5925 - val_acc: 0.7013\n",
      "Epoch 29/140\n",
      "0s - loss: 0.5595 - acc: 0.7150 - val_loss: 0.5914 - val_acc: 0.6948\n",
      "Epoch 30/140\n",
      "0s - loss: 0.5610 - acc: 0.7264 - val_loss: 0.5829 - val_acc: 0.6883\n",
      "Epoch 31/140\n",
      "0s - loss: 0.5565 - acc: 0.7231 - val_loss: 0.6134 - val_acc: 0.6883\n",
      "Epoch 32/140\n",
      "0s - loss: 0.5634 - acc: 0.7166 - val_loss: 0.5892 - val_acc: 0.6948\n",
      "Epoch 33/140\n",
      "0s - loss: 0.5590 - acc: 0.7166 - val_loss: 0.5837 - val_acc: 0.6883\n",
      "Epoch 34/140\n",
      "0s - loss: 0.5602 - acc: 0.7182 - val_loss: 0.5824 - val_acc: 0.7143\n",
      "Epoch 35/140\n",
      "0s - loss: 0.5632 - acc: 0.7166 - val_loss: 0.5801 - val_acc: 0.7338\n",
      "Epoch 36/140\n",
      "0s - loss: 0.5526 - acc: 0.7166 - val_loss: 0.5820 - val_acc: 0.7013\n",
      "Epoch 37/140\n",
      "0s - loss: 0.5547 - acc: 0.7345 - val_loss: 0.5741 - val_acc: 0.7273\n",
      "Epoch 38/140\n",
      "0s - loss: 0.5508 - acc: 0.7378 - val_loss: 0.5708 - val_acc: 0.7013\n",
      "Epoch 39/140\n",
      "0s - loss: 0.5485 - acc: 0.7345 - val_loss: 0.5752 - val_acc: 0.7208\n",
      "Epoch 40/140\n",
      "0s - loss: 0.5578 - acc: 0.7394 - val_loss: 0.5774 - val_acc: 0.6818\n",
      "Epoch 41/140\n",
      "0s - loss: 0.5461 - acc: 0.7508 - val_loss: 0.5842 - val_acc: 0.7338\n",
      "Epoch 42/140\n",
      "0s - loss: 0.5541 - acc: 0.7101 - val_loss: 0.5684 - val_acc: 0.6948\n",
      "Epoch 43/140\n",
      "0s - loss: 0.5487 - acc: 0.7329 - val_loss: 0.5819 - val_acc: 0.7013\n",
      "Epoch 44/140\n",
      "0s - loss: 0.5469 - acc: 0.7427 - val_loss: 0.5711 - val_acc: 0.6818\n",
      "Epoch 45/140\n",
      "0s - loss: 0.5432 - acc: 0.7378 - val_loss: 0.5749 - val_acc: 0.6948\n",
      "Epoch 46/140\n",
      "0s - loss: 0.5483 - acc: 0.7427 - val_loss: 0.5748 - val_acc: 0.7013\n",
      "Epoch 47/140\n",
      "0s - loss: 0.5481 - acc: 0.7394 - val_loss: 0.5721 - val_acc: 0.7273\n",
      "Epoch 48/140\n",
      "0s - loss: 0.5403 - acc: 0.7296 - val_loss: 0.5673 - val_acc: 0.7013\n",
      "Epoch 49/140\n",
      "0s - loss: 0.5362 - acc: 0.7345 - val_loss: 0.5707 - val_acc: 0.7208\n",
      "Epoch 50/140\n",
      "0s - loss: 0.5384 - acc: 0.7508 - val_loss: 0.5680 - val_acc: 0.7273\n",
      "Epoch 51/140\n",
      "0s - loss: 0.5533 - acc: 0.7280 - val_loss: 0.5645 - val_acc: 0.7013\n",
      "Epoch 52/140\n",
      "0s - loss: 0.5345 - acc: 0.7345 - val_loss: 0.5682 - val_acc: 0.6883\n",
      "Epoch 53/140\n",
      "0s - loss: 0.5381 - acc: 0.7199 - val_loss: 0.5621 - val_acc: 0.7143\n",
      "Epoch 54/140\n",
      "0s - loss: 0.5373 - acc: 0.7427 - val_loss: 0.5698 - val_acc: 0.7208\n",
      "Epoch 55/140\n",
      "0s - loss: 0.5328 - acc: 0.7378 - val_loss: 0.5661 - val_acc: 0.7013\n",
      "Epoch 56/140\n",
      "0s - loss: 0.5343 - acc: 0.7459 - val_loss: 0.5666 - val_acc: 0.7208\n",
      "Epoch 57/140\n",
      "0s - loss: 0.5349 - acc: 0.7476 - val_loss: 0.5859 - val_acc: 0.6948\n",
      "Epoch 58/140\n",
      "0s - loss: 0.5299 - acc: 0.7427 - val_loss: 0.5649 - val_acc: 0.7078\n",
      "Epoch 59/140\n",
      "0s - loss: 0.5346 - acc: 0.7443 - val_loss: 0.5555 - val_acc: 0.7143\n",
      "Epoch 60/140\n",
      "0s - loss: 0.5304 - acc: 0.7378 - val_loss: 0.5671 - val_acc: 0.7143\n",
      "Epoch 61/140\n",
      "0s - loss: 0.5300 - acc: 0.7492 - val_loss: 0.5682 - val_acc: 0.6948\n",
      "Epoch 62/140\n",
      "0s - loss: 0.5274 - acc: 0.7573 - val_loss: 0.5647 - val_acc: 0.7013\n",
      "Epoch 63/140\n",
      "0s - loss: 0.5218 - acc: 0.7476 - val_loss: 0.5636 - val_acc: 0.7208\n",
      "Epoch 64/140\n",
      "0s - loss: 0.5312 - acc: 0.7280 - val_loss: 0.5715 - val_acc: 0.7208\n",
      "Epoch 65/140\n",
      "0s - loss: 0.5290 - acc: 0.7459 - val_loss: 0.5615 - val_acc: 0.7208\n",
      "Epoch 66/140\n",
      "0s - loss: 0.5252 - acc: 0.7459 - val_loss: 0.5600 - val_acc: 0.7273\n",
      "Epoch 67/140\n",
      "0s - loss: 0.5251 - acc: 0.7378 - val_loss: 0.5763 - val_acc: 0.6883\n",
      "Epoch 68/140\n",
      "0s - loss: 0.5205 - acc: 0.7476 - val_loss: 0.5566 - val_acc: 0.7208\n",
      "Epoch 69/140\n",
      "0s - loss: 0.5214 - acc: 0.7443 - val_loss: 0.5535 - val_acc: 0.7338\n",
      "Epoch 70/140\n",
      "0s - loss: 0.5194 - acc: 0.7492 - val_loss: 0.5612 - val_acc: 0.7273\n",
      "Epoch 71/140\n",
      "0s - loss: 0.5277 - acc: 0.7443 - val_loss: 0.5538 - val_acc: 0.7208\n",
      "Epoch 72/140\n",
      "0s - loss: 0.5265 - acc: 0.7508 - val_loss: 0.5750 - val_acc: 0.7078\n",
      "Epoch 73/140\n",
      "0s - loss: 0.5300 - acc: 0.7443 - val_loss: 0.5555 - val_acc: 0.7468\n",
      "Epoch 74/140\n",
      "0s - loss: 0.5196 - acc: 0.7476 - val_loss: 0.5558 - val_acc: 0.7273\n",
      "Epoch 75/140\n",
      "0s - loss: 0.5199 - acc: 0.7508 - val_loss: 0.5562 - val_acc: 0.7208\n",
      "Epoch 76/140\n",
      "0s - loss: 0.5171 - acc: 0.7524 - val_loss: 0.5769 - val_acc: 0.6883\n",
      "Epoch 77/140\n",
      "0s - loss: 0.5248 - acc: 0.7476 - val_loss: 0.5491 - val_acc: 0.7403\n",
      "Epoch 78/140\n",
      "0s - loss: 0.5151 - acc: 0.7524 - val_loss: 0.5478 - val_acc: 0.7532\n",
      "Epoch 79/140\n",
      "0s - loss: 0.5122 - acc: 0.7573 - val_loss: 0.5740 - val_acc: 0.7143\n",
      "Epoch 80/140\n",
      "0s - loss: 0.5309 - acc: 0.7329 - val_loss: 0.5462 - val_acc: 0.7208\n",
      "Epoch 81/140\n",
      "0s - loss: 0.5107 - acc: 0.7590 - val_loss: 0.5621 - val_acc: 0.7338\n",
      "Epoch 82/140\n",
      "0s - loss: 0.5182 - acc: 0.7476 - val_loss: 0.5591 - val_acc: 0.7208\n",
      "Epoch 83/140\n",
      "0s - loss: 0.5182 - acc: 0.7541 - val_loss: 0.5475 - val_acc: 0.7273\n",
      "Epoch 84/140\n",
      "0s - loss: 0.5171 - acc: 0.7590 - val_loss: 0.5483 - val_acc: 0.7532\n",
      "Epoch 85/140\n",
      "0s - loss: 0.5169 - acc: 0.7345 - val_loss: 0.5514 - val_acc: 0.7208\n",
      "Epoch 86/140\n",
      "0s - loss: 0.5107 - acc: 0.7459 - val_loss: 0.5585 - val_acc: 0.7208\n",
      "Epoch 87/140\n",
      "0s - loss: 0.5213 - acc: 0.7329 - val_loss: 0.5497 - val_acc: 0.7273\n",
      "Epoch 88/140\n",
      "0s - loss: 0.5151 - acc: 0.7524 - val_loss: 0.5454 - val_acc: 0.7532\n",
      "Epoch 89/140\n",
      "0s - loss: 0.5103 - acc: 0.7622 - val_loss: 0.5451 - val_acc: 0.7403\n",
      "Epoch 90/140\n",
      "0s - loss: 0.5081 - acc: 0.7622 - val_loss: 0.5523 - val_acc: 0.7338\n",
      "Epoch 91/140\n",
      "0s - loss: 0.5077 - acc: 0.7557 - val_loss: 0.5454 - val_acc: 0.7468\n",
      "Epoch 92/140\n",
      "0s - loss: 0.5167 - acc: 0.7476 - val_loss: 0.5479 - val_acc: 0.7273\n",
      "Epoch 93/140\n",
      "0s - loss: 0.5126 - acc: 0.7541 - val_loss: 0.5464 - val_acc: 0.7338\n",
      "Epoch 94/140\n",
      "0s - loss: 0.5048 - acc: 0.7622 - val_loss: 0.5418 - val_acc: 0.7468\n",
      "Epoch 95/140\n",
      "0s - loss: 0.5056 - acc: 0.7606 - val_loss: 0.5449 - val_acc: 0.7403\n",
      "Epoch 96/140\n",
      "0s - loss: 0.5078 - acc: 0.7557 - val_loss: 0.5379 - val_acc: 0.7403\n",
      "Epoch 97/140\n",
      "0s - loss: 0.5023 - acc: 0.7573 - val_loss: 0.5541 - val_acc: 0.7273\n",
      "Epoch 98/140\n",
      "0s - loss: 0.5116 - acc: 0.7590 - val_loss: 0.5740 - val_acc: 0.7078\n",
      "Epoch 99/140\n",
      "0s - loss: 0.5035 - acc: 0.7704 - val_loss: 0.5412 - val_acc: 0.7468\n",
      "Epoch 100/140\n",
      "0s - loss: 0.5007 - acc: 0.7655 - val_loss: 0.5436 - val_acc: 0.7403\n",
      "Epoch 101/140\n",
      "0s - loss: 0.5019 - acc: 0.7557 - val_loss: 0.5584 - val_acc: 0.7143\n",
      "Epoch 102/140\n",
      "0s - loss: 0.5019 - acc: 0.7541 - val_loss: 0.5399 - val_acc: 0.7468\n",
      "Epoch 103/140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0s - loss: 0.5060 - acc: 0.7524 - val_loss: 0.5363 - val_acc: 0.7662\n",
      "Epoch 104/140\n",
      "0s - loss: 0.5052 - acc: 0.7573 - val_loss: 0.5484 - val_acc: 0.7403\n",
      "Epoch 105/140\n",
      "0s - loss: 0.5050 - acc: 0.7590 - val_loss: 0.5332 - val_acc: 0.7597\n",
      "Epoch 106/140\n",
      "0s - loss: 0.5045 - acc: 0.7492 - val_loss: 0.5298 - val_acc: 0.7662\n",
      "Epoch 107/140\n",
      "0s - loss: 0.5062 - acc: 0.7655 - val_loss: 0.5299 - val_acc: 0.7468\n",
      "Epoch 108/140\n",
      "0s - loss: 0.5038 - acc: 0.7508 - val_loss: 0.5440 - val_acc: 0.7338\n",
      "Epoch 109/140\n",
      "0s - loss: 0.5040 - acc: 0.7590 - val_loss: 0.5414 - val_acc: 0.7338\n",
      "Epoch 110/140\n",
      "0s - loss: 0.4981 - acc: 0.7573 - val_loss: 0.5315 - val_acc: 0.7403\n",
      "Epoch 111/140\n",
      "0s - loss: 0.5012 - acc: 0.7606 - val_loss: 0.5363 - val_acc: 0.7662\n",
      "Epoch 112/140\n",
      "0s - loss: 0.4993 - acc: 0.7492 - val_loss: 0.5320 - val_acc: 0.7403\n",
      "Epoch 113/140\n",
      "0s - loss: 0.4987 - acc: 0.7671 - val_loss: 0.5482 - val_acc: 0.7143\n",
      "Epoch 114/140\n",
      "0s - loss: 0.5147 - acc: 0.7508 - val_loss: 0.5425 - val_acc: 0.7403\n",
      "Epoch 115/140\n",
      "0s - loss: 0.4934 - acc: 0.7687 - val_loss: 0.5385 - val_acc: 0.7403\n",
      "Epoch 116/140\n",
      "0s - loss: 0.4915 - acc: 0.7606 - val_loss: 0.5308 - val_acc: 0.7468\n",
      "Epoch 117/140\n",
      "0s - loss: 0.4977 - acc: 0.7638 - val_loss: 0.5393 - val_acc: 0.7468\n",
      "Epoch 118/140\n",
      "0s - loss: 0.4931 - acc: 0.7573 - val_loss: 0.5280 - val_acc: 0.7662\n",
      "Epoch 119/140\n",
      "0s - loss: 0.4954 - acc: 0.7541 - val_loss: 0.5265 - val_acc: 0.7597\n",
      "Epoch 120/140\n",
      "0s - loss: 0.4918 - acc: 0.7573 - val_loss: 0.5249 - val_acc: 0.7403\n",
      "Epoch 121/140\n",
      "0s - loss: 0.4969 - acc: 0.7573 - val_loss: 0.5346 - val_acc: 0.7403\n",
      "Epoch 122/140\n",
      "0s - loss: 0.4905 - acc: 0.7590 - val_loss: 0.5260 - val_acc: 0.7727\n",
      "Epoch 123/140\n",
      "0s - loss: 0.5012 - acc: 0.7492 - val_loss: 0.5808 - val_acc: 0.7013\n",
      "Epoch 124/140\n",
      "0s - loss: 0.4948 - acc: 0.7818 - val_loss: 0.5337 - val_acc: 0.7403\n",
      "Epoch 125/140\n",
      "0s - loss: 0.4836 - acc: 0.7671 - val_loss: 0.5228 - val_acc: 0.7597\n",
      "Epoch 126/140\n",
      "0s - loss: 0.4843 - acc: 0.7638 - val_loss: 0.5298 - val_acc: 0.7338\n",
      "Epoch 127/140\n",
      "0s - loss: 0.4855 - acc: 0.7573 - val_loss: 0.5355 - val_acc: 0.7403\n",
      "Epoch 128/140\n",
      "0s - loss: 0.4925 - acc: 0.7704 - val_loss: 0.5191 - val_acc: 0.7532\n",
      "Epoch 129/140\n",
      "0s - loss: 0.4902 - acc: 0.7655 - val_loss: 0.5181 - val_acc: 0.7468\n",
      "Epoch 130/140\n",
      "0s - loss: 0.4867 - acc: 0.7704 - val_loss: 0.5326 - val_acc: 0.7403\n",
      "Epoch 131/140\n",
      "0s - loss: 0.4945 - acc: 0.7606 - val_loss: 0.5514 - val_acc: 0.7208\n",
      "Epoch 132/140\n",
      "0s - loss: 0.4854 - acc: 0.7573 - val_loss: 0.5352 - val_acc: 0.7662\n",
      "Epoch 133/140\n",
      "0s - loss: 0.4885 - acc: 0.7638 - val_loss: 0.5200 - val_acc: 0.7532\n",
      "Epoch 134/140\n",
      "0s - loss: 0.4868 - acc: 0.7573 - val_loss: 0.5191 - val_acc: 0.7468\n",
      "Epoch 135/140\n",
      "0s - loss: 0.4851 - acc: 0.7622 - val_loss: 0.5282 - val_acc: 0.7532\n",
      "Epoch 136/140\n",
      "0s - loss: 0.4820 - acc: 0.7687 - val_loss: 0.5172 - val_acc: 0.7597\n",
      "Epoch 137/140\n",
      "0s - loss: 0.4803 - acc: 0.7655 - val_loss: 0.5450 - val_acc: 0.7532\n",
      "Epoch 138/140\n",
      "0s - loss: 0.4917 - acc: 0.7492 - val_loss: 0.5560 - val_acc: 0.7273\n",
      "Epoch 139/140\n",
      "0s - loss: 0.4839 - acc: 0.7687 - val_loss: 0.5130 - val_acc: 0.7468\n",
      "Epoch 140/140\n",
      "0s - loss: 0.4841 - acc: 0.7655 - val_loss: 0.5262 - val_acc: 0.7597\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "history = model.fit(X, Y, validation_split=0.20,epochs=140, batch_size=10,  verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/768 [>.............................] - ETA: 0s\n",
      "acc: 76.82%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, acc_t = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], acc_t*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy: 76.82%\n"
     ]
    }
   ],
   "source": [
    "# calculate predictions\n",
    "probabilities = model.predict(X)\n",
    "predictions = [float(round(x[0])) for x in probabilities]\n",
    "accuracy = numpy.mean(predictions == Y)\n",
    "print(\"Prediction Accuracy: %.2f%%\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    " print(history.history.keys())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.optimizers.SGD object at 0x7fc215b0acf8>\n",
      "Accuracy: 65.10%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRE4WZmY2ov8f/sDEvyV6CY4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc215835128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc214795cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's create a plot to evaluate the performance\n",
    "print (model.optimizer)\n",
    "print(\"Accuracy: %.2f%%\" % (acc_t*100))\n",
    "plotPerformance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's try a new optimizer \n",
    "##### Let's play with optimization algorithms and epoch numbers! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model.add(Dense(units=64, input_dim=100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/models.py:848: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (768, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils.np_utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ef94a23816bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1520\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1391\u001b[0m         _check_loss_and_target_compatibility(y,\n\u001b[1;32m   1392\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_loss_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m                                              self._feed_output_shapes)\n\u001b[0m\u001b[1;32m   1394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 raise ValueError(\n\u001b[1;32m    276\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (768, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils.np_utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "model.fit(X, Y, nb_epoch=10, batch_size= 100,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
